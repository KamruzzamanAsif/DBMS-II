{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from csv import reader\n",
    "import math\n",
    "import random \n",
    "from random import randint, seed \n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    with open(filename, 'rt') as read_obj:\n",
    "        csv_reader = csv.reader(read_obj) # Return a reader object which will\n",
    "                                        # iterate over lines in the given csvfile\n",
    "        training_data = list(csv_reader)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(row):  \n",
    "    row = [float(x.strip()) for x in row]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(data_set):\n",
    "    counts = {}\n",
    "    for row in data_set:\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data_set):\n",
    "    counts = class_counts(data_set)\n",
    "    entropy = 0\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(data_set))\n",
    "        entropy -= math.log(prob_of_lbl, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "\n",
    "    def __init__(self, index, value):\n",
    "        self.index = index\n",
    "        self.value = value\n",
    "\n",
    "    def match(self, example):\n",
    "        val = example[self.index]\n",
    "        return val >= self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_partition(data_set, question):\n",
    "    right, left = [], []\n",
    "    for row in data_set:\n",
    "        if question.match(row):\n",
    "            right.append(row)\n",
    "        else:\n",
    "            left.append(row)\n",
    "    return right, left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gain(right, left, current_data_set_entropy):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_data_set_entropy - p * calculate_entropy(left) - (1 - p) * calculate_entropy(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data_set):\n",
    "    best_gain = 0\n",
    "    split_question = None\n",
    "    current_data_set_entropy = calculate_entropy(data_set)\n",
    "    number_of_features = len(data_set[0]) - 1\n",
    "\n",
    "    for column in range(number_of_features):\n",
    "        column_values = set([row[column] for row in data_set])\n",
    "        for value in column_values:\n",
    "            question = Question(column, value)\n",
    "            right, left = make_partition(data_set, question)\n",
    "            if len(right) == 0 or len(left) == 0:\n",
    "                continue\n",
    "\n",
    "            gain = calculate_gain(right, left, current_data_set_entropy)\n",
    "            \n",
    "            if gain > best_gain:\n",
    "                best_gain, split_question = gain, question\n",
    "    \n",
    "    return best_gain, split_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class leaf_node:\n",
    "    def __init__(self, data_set):\n",
    "       self.predictions = class_counts(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_node:\n",
    "    def __init__(self, question, right, left):\n",
    "        self.question = question\n",
    "        self.right = right\n",
    "        self.left = left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data_set):\n",
    "    info_gain, question = find_best_split(data_set)\n",
    "\n",
    "    if info_gain == 0:\n",
    "        return leaf_node(data_set)\n",
    "    \n",
    "    right_split_data_set, left_split_data_set = make_partition(data_set, question)\n",
    "    right_branch = build_tree(right_split_data_set)\n",
    "    left_branch = build_tree(left_split_data_set)\n",
    "    return decision_node(question, right_branch, left_branch) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    if isinstance(node, leaf_node):\n",
    "        print(spacing + \"Node class and count: \", node.predictions)\n",
    "        return\n",
    "    print(spacing + 'index: ' + str(node.question.index) +\n",
    "          ' value: ' + str(node.question.value))\n",
    "\n",
    "    print(spacing + '--> greater than:')\n",
    "    print_tree(node.right, spacing + \"  \")\n",
    "\n",
    "    print(spacing + '--> less than:')\n",
    "    print_tree(node.left, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "\n",
    "    if isinstance(node, leaf_node):\n",
    "        return node.predictions\n",
    "\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.right)\n",
    "    else:\n",
    "        return classify(row, node.left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurary:  100.0 %\n",
      "accurary:  88.88888888888889 %\n",
      "accurary:  94.44444444444444 %\n",
      "accurary:  88.23529411764706 %\n",
      "accurary:  88.23529411764706 %\n",
      "accurary:  94.11764705882352 %\n",
      "accurary:  100.0 %\n",
      "accurary:  82.35294117647058 %\n",
      "accurary:  88.23529411764706 %\n",
      "accurary:  82.35294117647058 %\n",
      "\n",
      "*********Final Accuracy********\n",
      "\n",
      "average accuracy:  90.68627450980392 %\n"
     ]
    }
   ],
   "source": [
    "#### Main ####\n",
    "initial_data_set = readData('wine.csv') # here dataset contains data values as strings\n",
    "#so we convert the string values to floats\n",
    "data_set = []\n",
    "for row in initial_data_set:\n",
    "    row = convert_to_float(row)\n",
    "    data_set.append(row)\n",
    " \n",
    "# now we will do k-fold \n",
    "# for now k=10 \n",
    "k = 10\n",
    "folds = []\n",
    "for i in range(k):\n",
    "    folds.append([])\n",
    "for i in range(len(data_set)):\n",
    "    folds[i % k].append(data_set[i])\n",
    "\n",
    "# now we will do cross validation\n",
    "total_accuracy = 0.0\n",
    "for group in folds:\n",
    "    # train test splits\n",
    "    train_data = list(folds)\n",
    "    train_data.remove(group)\n",
    "    train_data = sum(train_data, [])\n",
    "    test_data = group  \n",
    "\n",
    "\n",
    "    # let we will make 5 decision trees\n",
    "    num_of_decision_tree = 5\n",
    "    n_features = int(sqrt(len(train_data[0])-1))\n",
    "    trees = list()\n",
    "\n",
    "    # here we will build forest trees and aslo test the dataset\n",
    "    # first build trees and then test the rows \n",
    "    total_row = 0\n",
    "    total_matched = 0\n",
    "    for t_row in test_data:\n",
    "        total_row += 1\n",
    "        forest_matched = 0\n",
    "        forest_unmatched = 0\n",
    "        for i in range(num_of_decision_tree):\n",
    "            # get the number of rows and columns in the data\n",
    "            num_rows = len(train_data)\n",
    "            num_cols = len(train_data[0])-1   # to avoid taking feature column we -1\n",
    "\n",
    "            # create a list of row indices and randomly shuffle it\n",
    "            row_indices = list(range(num_rows))\n",
    "            random.shuffle(row_indices)\n",
    "\n",
    "            # take 50% of rows\n",
    "            num_tree_rows = int(0.5 * num_rows)\n",
    "            ith_tree_rows_indices = row_indices[:num_tree_rows]\n",
    "\n",
    "            # columns\n",
    "            ith_tree_cols_indices = random.sample(range(num_cols), n_features)\n",
    "\n",
    "            # now our ith tree train_dataset\n",
    "            # extract the last column\n",
    "            feature_column = []\n",
    "            for i in ith_tree_rows_indices:\n",
    "                feature_column.append(train_data[i][-1])\n",
    "\n",
    "            ith_train_set = [[train_data[i][j] for j in ith_tree_cols_indices] for i in ith_tree_rows_indices]\n",
    "            for row in ith_train_set:\n",
    "                row.append(feature_column[ith_train_set.index(row)])\n",
    "\n",
    "            # now build tree\n",
    "            ith_d_tree = build_tree(ith_train_set)\n",
    "            trees.append(ith_d_tree)  # if you want you can print the trees later from the tree list\n",
    "\n",
    "            # now ith-test data\n",
    "            # here we done a very significant work\n",
    "            # we take the test_row accorind to training data column indexes\n",
    "            # if we don't take it it will show error answers\n",
    "            test_row = []\n",
    "            for index in ith_tree_cols_indices:\n",
    "                value = t_row[index]\n",
    "                test_row.append(value)\n",
    "            test_row.append(t_row[-1])\n",
    "            \n",
    "            # now test the row for this ith-d_tree\n",
    "            classified = classify(test_row, ith_d_tree)\n",
    "            for lbl in classified.keys():\n",
    "                if lbl == test_row[-1]:\n",
    "                    forest_matched += 1\n",
    "                else:\n",
    "                    forest_unmatched += 1\n",
    "\n",
    "        # we take the maximum decision form the trees\n",
    "        if forest_matched > forest_unmatched:\n",
    "            total_matched += 1\n",
    "\n",
    "    accuracy = total_matched/total_row*100\n",
    "    total_accuracy += accuracy\n",
    "    print('accurary: ', accuracy, '%')\n",
    "\n",
    "\n",
    "print(\"\\n*********Final Accuracy********\\n\")\n",
    "average_accuracy = total_accuracy / k\n",
    "print('average accuracy: ', average_accuracy, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
